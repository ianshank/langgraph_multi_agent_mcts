name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"

jobs:
  lint:
    name: Lint with Ruff
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install ruff
        run: pip install ruff

      - name: Run ruff linter
        run: ruff check . --output-format=github

      - name: Run ruff formatter check
        run: ruff format --check .

  type-check:
    name: Type Check with MyPy
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install mypy
          pip install types-psutil types-requests
          pip install pydantic>=2.0.0 pydantic-settings>=2.0.0
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f pyproject.toml ]; then pip install -e .; fi

      - name: Run mypy
        run: mypy src/ --ignore-missing-imports --no-error-summary || true
        continue-on-error: true


  security-scan:
    name: Security Scan with Bandit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install bandit
        run: pip install bandit[toml]

      - name: Run bandit security scan
        run: bandit -r src/ -f json -o bandit-report.json || true

      - name: Upload bandit report
        uses: actions/upload-artifact@v4
        with:
          name: bandit-security-report
          path: bandit-report.json

      - name: Display high severity issues
        run: |
          if [ -f bandit-report.json ]; then
            python -c "import json,sys; d=json.load(open('bandit-report.json')); hs=[r for r in d.get('results',[]) if r.get('issue_severity')=='HIGH']; print('HIGH SEVERITY ISSUES FOUND:' if hs else 'No high severity issues found'); [print('  - {}:{}: {}'.format(r.get('filename'), r.get('line_number'), r.get('issue_text'))) for r in hs]; sys.exit(1 if hs else 0)"
          fi

  dependency-audit:
    name: Dependency Vulnerability Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install pip-audit
        run: pip install pip-audit

      - name: Install project dependencies
        run: |
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f pyproject.toml ]; then pip install -e .; fi

      - name: Run pip-audit
        run: pip-audit --format=json --output=pip-audit-report.json || true

      - name: Upload pip-audit report
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit-report
          path: pip-audit-report.json

      - name: Check for critical vulnerabilities
        run: |
          if [ -f pip-audit-report.json ]; then
            python -c "import json,sys; d=json.load(open('pip-audit-report.json')); crit=[dep for dep in d.get('dependencies',[]) if any(v.get('severity','')=='CRITICAL' for v in dep.get('vulns',[]))]; print('CRITICAL VULNERABILITIES FOUND:' if crit else 'No critical vulnerabilities found'); [print('  - {}=={}'.format(dep.get('name'), dep.get('version'))) for dep in crit]; sys.exit(1 if crit else 0)"
          fi

  test:
    name: Tests with Pytest
    runs-on: ubuntu-latest
    needs: [lint]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install pytest pytest-cov pytest-asyncio pytest-mock
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f pyproject.toml ]; then pip install -e .; fi

      - name: Create test directory if not exists
        run: mkdir -p tests

      - name: Run tests with coverage
        run: |
          pytest tests/ \
            --cov=src \
            --cov-report=xml:coverage.xml \
            --cov-report=html:htmlcov \
            --cov-report=term-missing \
            --junitxml=junit.xml \
            -v \
            || true
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
          WANDB_MODE: disabled  # Disable W&B in CI tests
          LANGCHAIN_TRACING_V2: false  # Disable LangSmith in CI tests

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: htmlcov/

      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: junit.xml

  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install pytest pytest-asyncio
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f pyproject.toml ]; then pip install -e .; fi

      - name: Run integration tests
        run: |
          if [ -d tests/integration ]; then
            pytest tests/integration/ -v --tb=short
          else
            echo "No integration tests found"
          fi
        env:
          CI: true
          LOG_LEVEL: INFO

  build-check:
    name: Build Verification
    runs-on: ubuntu-latest
    needs: [lint, type-check]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install build tools
        run: pip install build wheel

      - name: Verify package structure
        run: |
          # Check that all __init__.py files exist
          find src -type d -exec test -f {}/__init__.py \; -print | head -20

      - name: Try building package
        run: |
          if [ -f pyproject.toml ]; then
            python -m build --no-isolation --wheel
            echo "Package built successfully"
          else
            echo "No pyproject.toml found, skipping build"
          fi

  summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [lint, type-check, security-scan, dependency-audit, test]
    if: always()
    steps:
      - name: Check all job results
        run: |
          echo "=== CI Pipeline Summary ==="
          echo "Lint: ${{ needs.lint.result }}"
          echo "Type Check: ${{ needs.type-check.result }}"
          echo "Security Scan: ${{ needs.security-scan.result }}"
          echo "Dependency Audit: ${{ needs.dependency-audit.result }}"
          echo "Tests: ${{ needs.test.result }}"

          # Fail if any critical job failed
          if [[ "${{ needs.lint.result }}" == "failure" ]] || \
             [[ "${{ needs.test.result }}" == "failure" ]]; then
            echo "Critical job failed!"
            exit 1
          fi

          echo "All critical checks passed!"

# ============================================================================
# RAG Evaluation Workflow (On-Demand)
# ============================================================================
# This workflow runs comprehensive RAG evaluations with ragas metrics.
# Triggered manually or on schedule for cost control.

  rag-eval:
    name: RAG Evaluation with Ragas
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event.schedule
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -e .

      - name: Run RAG evaluation (baseline)
        run: |
          python scripts/evaluate_rag.py \
            --dataset rag-eval-dataset \
            --limit 50 \
            --mcts-enabled false \
            --output results/baseline_eval.csv
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
          LANGCHAIN_TRACING_V2: true
          WANDB_MODE: online
        continue-on-error: true

      - name: Run RAG evaluation (MCTS enabled)
        run: |
          python scripts/evaluate_rag.py \
            --dataset rag-eval-dataset \
            --limit 50 \
            --mcts-enabled true \
            --output results/mcts_eval.csv
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
          LANGCHAIN_TRACING_V2: true
          WANDB_MODE: online
        continue-on-error: true

      - name: Upload evaluation results
        uses: actions/upload-artifact@v4
        with:
          name: rag-eval-results
          path: results/*.csv
        if: always()
