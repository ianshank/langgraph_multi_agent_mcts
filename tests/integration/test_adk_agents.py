"""
Integration tests for Google ADK Agents.

Tests the integration of ADK agents with the multi-agent MCTS framework,
including user journey tests and agent collaboration scenarios.
"""

import asyncio
import os
from unittest.mock import AsyncMock, Mock, patch

import pytest

# Check if google-adk is actually installed
try:
    import google.adk  # noqa: F401
    GOOGLE_ADK_INSTALLED = True
except ImportError:
    GOOGLE_ADK_INSTALLED = False

# Mock ADK imports if not available
try:
    from src.integrations.google_adk.agents.data_science import DataScienceAgent
    from src.integrations.google_adk.agents.deep_search import DeepSearchAgent
    from src.integrations.google_adk.agents.ml_engineering import MLEngineeringAgent
    from src.integrations.google_adk.base import ADKAgentAdapter, ADKConfig
    ADK_AVAILABLE = True and GOOGLE_ADK_INSTALLED
except ImportError:
    ADK_AVAILABLE = False
    ADKAgentAdapter = Mock
    ADKConfig = Mock
    DeepSearchAgent = Mock
    MLEngineeringAgent = Mock
    DataScienceAgent = Mock

from src.adapters.llm.base import BaseLLMClient, LLMResponse
from src.framework.graph import GraphBuilder


# Skip entire module if google-adk is not installed
pytestmark = pytest.mark.skipif(
    not GOOGLE_ADK_INSTALLED,
    reason="google-adk package not installed. Install with: pip install google-adk"
)


class TestADKAgentIntegration:
    """Test ADK agent integration with the framework."""

    @pytest.fixture
    def mock_llm_client(self):
        """Create a mock LLM client."""
        client = Mock(spec=BaseLLMClient)
        client.generate.return_value = LLMResponse(
            text="Mock response",
            raw_response={"choices": [{"message": {"content": "Mock response"}}]},
        )
        client.generate_async = AsyncMock(return_value=LLMResponse(
            text="Mock async response",
            raw_response={"choices": [{"message": {"content": "Mock async response"}}]},
        ))
        return client

    @pytest.fixture
    def adk_config(self):
        """Create ADK configuration.

        Note: Google Cloud credentials are handled via GOOGLE_APPLICATION_CREDENTIALS
        environment variable automatically by the Google Cloud client libraries.
        """
        if ADK_AVAILABLE:
            return ADKConfig(
                project_id=os.environ.get("GOOGLE_CLOUD_PROJECT", "test-project"),
                location="us-central1",
            )
        return Mock()

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_deep_search_agent_initialization(self, adk_config, mock_llm_client):
        """Test DeepSearchAgent initialization and basic functionality."""
        with patch('src.integrations.google_adk.agents.deep_search.vertexai', create=True) as mock_vertexai:
            agent = DeepSearchAgent(config=adk_config)

            assert agent is not None
            assert agent.config == adk_config
            assert agent.llm_client == mock_llm_client

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_ml_engineering_agent_task_execution(self, adk_config, mock_llm_client):
        """Test MLEngineeringAgent task execution."""
        with patch('src.integrations.google_adk.agents.ml_engineering.vertexai', create=True) as mock_vertexai:
            agent = MLEngineeringAgent(config=adk_config)

            # Mock task execution
            result = await agent.execute_task(
                task="Optimize model training pipeline",
                context={"model_type": "transformer", "dataset_size": "10GB"}
            )

            assert result is not None
            assert "response" in result or isinstance(result, str)

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_data_science_agent_analysis(self, adk_config, mock_llm_client):
        """Test DataScienceAgent data analysis capabilities."""
        with patch('src.integrations.google_adk.agents.data_science.vertexai', create=True) as mock_vertexai:
            agent = DataScienceAgent(config=adk_config)

            # Mock data analysis
            result = await agent.analyze_data(
                query="Analyze customer churn patterns",
                data_source="bigquery://project.dataset.table"
            )

            assert result is not None
            assert isinstance(result, (dict, str))


class TestADKUserJourneys:
    """Test end-to-end user journeys with ADK agents."""

    @pytest.fixture
    def mock_llm_client(self):
        """Create a mock LLM client for user journey tests."""
        client = Mock(spec=BaseLLMClient)
        client.generate.return_value = LLMResponse(
            text="Mock response",
            raw_response={"choices": [{"message": {"content": "Mock response"}}]},
        )
        client.generate_async = AsyncMock(return_value=LLMResponse(
            text="Mock async response",
            raw_response={"choices": [{"message": {"content": "Mock async response"}}]},
        ))
        return client

    @pytest.fixture
    def adk_config(self):
        """Create ADK configuration for user journey tests."""
        if ADK_AVAILABLE:
            return ADKConfig(
                project_id=os.environ.get("GOOGLE_CLOUD_PROJECT", "test-project"),
                location="us-central1",
            )
        return Mock()

    @pytest.fixture
    def graph_builder(self, mock_llm_client):
        """Create a mock GraphBuilder with llm_client for testing.

        Note: These tests only need access to llm_client, not a full GraphBuilder.
        """
        mock_builder = Mock()
        mock_builder.llm_client = mock_llm_client
        return mock_builder

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_research_and_development_journey(self, graph_builder, adk_config):
        """Test a complete R&D user journey using ADK agents."""
        with patch('src.integrations.google_adk.base.vertexai', create=True) as mock_vertexai:
            # Initialize agents
            deep_search = DeepSearchAgent(config=adk_config)
            ml_engineer = MLEngineeringAgent(config=adk_config)
            data_scientist = DataScienceAgent(config=adk_config)

            # User journey: Research -> Design -> Implement
            journey_steps = [
                {
                    "step": "Research",
                    "agent": deep_search,
                    "task": "Research latest advances in transformer architectures for NLP"
                },
                {
                    "step": "Design",
                    "agent": ml_engineer,
                    "task": "Design a scalable training pipeline for the new architecture"
                },
                {
                    "step": "Analysis",
                    "agent": data_scientist,
                    "task": "Analyze performance metrics and suggest optimizations"
                }
            ]

            results = []
            for step in journey_steps:
                # Mock agent execution
                with patch.object(step["agent"], 'execute', return_value={"response": f"Completed: {step['task']}"}):
                    result = await step["agent"].execute(step["task"])
                    results.append({
                        "step": step["step"],
                        "result": result
                    })

            assert len(results) == 3
            assert all("result" in r for r in results)

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_collaborative_problem_solving_journey(self, graph_builder, adk_config):
        """Test collaborative problem-solving between ADK agents."""
        with patch('src.integrations.google_adk.base.vertexai', create=True) as mock_vertexai:
            # Initialize agents
            agents = {
                "search": DeepSearchAgent(config=adk_config),
                "engineer": MLEngineeringAgent(config=adk_config),
                "analyst": DataScienceAgent(config=adk_config)
            }

            # Complex problem requiring collaboration
            problem = "Develop a real-time fraud detection system with explainable AI"

            # Collaborative workflow
            workflow = {
                "research_phase": {
                    "agent": "search",
                    "task": f"Research state-of-the-art fraud detection techniques for {problem}",
                    "output_to": ["engineer", "analyst"]
                },
                "design_phase": {
                    "agent": "engineer",
                    "task": "Design system architecture based on research findings",
                    "requires": ["research_phase"],
                    "output_to": ["analyst"]
                },
                "evaluation_phase": {
                    "agent": "analyst",
                    "task": "Evaluate proposed architecture and suggest improvements",
                    "requires": ["research_phase", "design_phase"]
                }
            }

            # Execute workflow
            results = {}
            for phase_name, phase_config in workflow.items():
                agent = agents[phase_config["agent"]]

                # Mock execution with context from previous phases
                context = {}
                if "requires" in phase_config:
                    for req in phase_config["requires"]:
                        if req in results:
                            context[req] = results[req]

                with patch.object(agent, 'execute', return_value={
                    "response": f"Completed: {phase_config['task']}",
                    "confidence": 0.85,
                    "context": context
                }):
                    results[phase_name] = await agent.execute(
                        phase_config["task"],
                        context=context
                    )

            assert len(results) == 3
            assert results["evaluation_phase"]["context"]
            assert "research_phase" in results["evaluation_phase"]["context"]
            assert "design_phase" in results["evaluation_phase"]["context"]

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_error_handling_and_recovery(self, graph_builder, adk_config):
        """Test error handling and recovery in ADK agent workflows."""
        with patch('src.integrations.google_adk.base.vertexai', create=True) as mock_vertexai:
            agent = DeepSearchAgent(config=adk_config)

            # Simulate various error conditions
            error_scenarios = [
                {
                    "error_type": "RateLimitError",
                    "should_retry": True,
                    "max_retries": 3
                },
                {
                    "error_type": "AuthenticationError",
                    "should_retry": False,
                    "max_retries": 0
                },
                {
                    "error_type": "TimeoutError",
                    "should_retry": True,
                    "max_retries": 2
                }
            ]

            for scenario in error_scenarios:
                with patch.object(agent, 'execute') as mock_execute:
                    if scenario["should_retry"]:
                        # Simulate successful retry
                        mock_execute.side_effect = [
                            Exception(scenario["error_type"]),
                            {"response": "Success after retry"}
                        ]
                    else:
                        # Simulate persistent failure
                        mock_execute.side_effect = Exception(scenario["error_type"])

                    try:
                        result = await agent.execute("Test task")
                        assert scenario["should_retry"]
                        assert result["response"] == "Success after retry"
                    except Exception as e:
                        assert not scenario["should_retry"]
                        assert str(e) == scenario["error_type"]


class TestADKAgentPerformance:
    """Test performance characteristics of ADK agents."""

    @pytest.fixture
    def adk_config(self):
        """Create ADK configuration for performance tests."""
        if ADK_AVAILABLE:
            return ADKConfig(
                project_id=os.environ.get("GOOGLE_CLOUD_PROJECT", "test-project"),
                location="us-central1",
            )
        return Mock()

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_parallel_agent_execution(self, adk_config):
        """Test parallel execution of multiple ADK agents."""
        with patch('src.integrations.google_adk.base.vertexai', create=True) as mock_vertexai:
            # Create multiple agents
            agents = [
                DeepSearchAgent(config=adk_config),
                MLEngineeringAgent(config=adk_config),
                DataScienceAgent(config=adk_config)
            ]

            # Define tasks for each agent
            tasks = [
                "Research quantum computing applications",
                "Design distributed training system",
                "Analyze model performance metrics"
            ]

            # Mock execution for each agent
            for agent in agents:
                agent.execute = AsyncMock(return_value={"response": "Task completed"})

            # Execute tasks in parallel
            results = await asyncio.gather(
                *[agent.execute(task) for agent, task in zip(agents, tasks)]
            )

            assert len(results) == 3
            assert all(r["response"] == "Task completed" for r in results)

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.benchmark(group="adk-agents")
    def test_agent_initialization_performance(self, benchmark, adk_config):
        """Benchmark ADK agent initialization time."""
        def init_agent():
            with patch('src.integrations.google_adk.base.vertexai', create=True):
                return DeepSearchAgent(config=adk_config)

        agent = benchmark(init_agent)
        assert agent is not None

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_agent_caching_effectiveness(self, adk_config):
        """Test caching effectiveness in ADK agents."""
        with patch('src.integrations.google_adk.base.vertexai', create=True) as mock_vertexai:
            agent = DeepSearchAgent(config=adk_config)
            agent.execute = AsyncMock(return_value={"response": "Cached response"})

            # First call - should hit the actual API
            result1 = await agent.execute("Research topic A")

            # Second identical call - should use cache
            result2 = await agent.execute("Research topic A")

            # Different call - should hit API again
            result3 = await agent.execute("Research topic B")

            # Verify caching behavior
            assert result1 == result2  # Same results for cached query
            assert agent.execute.call_count == 3  # All calls made (cache simulation)


class TestADKAgentSecurity:
    """Test security aspects of ADK agent integration."""

    @pytest.fixture
    def adk_config(self):
        """Create ADK configuration for security tests."""
        if ADK_AVAILABLE:
            return ADKConfig(
                project_id=os.environ.get("GOOGLE_CLOUD_PROJECT", "test-project"),
                location="us-central1",
            )
        return Mock()

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    def test_credential_handling(self, adk_config):
        """Test secure handling of credentials."""
        with patch('src.integrations.google_adk.base.vertexai', create=True) as mock_vertexai:
            # Ensure credentials are not exposed in logs or errors
            agent = DeepSearchAgent(config=adk_config)

            # Check that sensitive info is not in string representation
            agent_str = str(agent)
            assert "api_key" not in agent_str.lower()
            assert "credential" not in agent_str.lower()

            # Verify config validation
            if ADK_AVAILABLE:
                assert adk_config.project_id is not None

    @pytest.mark.skipif(not ADK_AVAILABLE, reason="ADK dependencies not available")
    @pytest.mark.asyncio
    async def test_input_sanitization(self, adk_config):
        """Test input sanitization in ADK agents."""
        with patch('src.integrations.google_adk.base.vertexai', create=True) as mock_vertexai:
            agent = DeepSearchAgent(config=adk_config)
            agent.execute = AsyncMock(return_value={"response": "Sanitized response"})

            # Test with potentially malicious inputs
            malicious_inputs = [
                "<script>alert('XSS')</script>",
                "'; DROP TABLE users; --",
                "../../../etc/passwd",
                "{{7*7}}"  # Template injection attempt
            ]

            for malicious_input in malicious_inputs:
                result = await agent.execute(malicious_input)
                # Verify the input is handled safely
                assert result["response"] == "Sanitized response"

                # Check that the agent was called (input was processed)
                agent.execute.assert_called()


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
